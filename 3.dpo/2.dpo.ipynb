{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03697c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '!'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import os\n",
    "\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "b = 4\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token_id = 0\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "733f6090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7fcaf278bc4b4a9bb1fe773aace500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/78577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41ff8ead56840d4917874aaba231fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/78577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['question', 'answer'],\n",
       "     num_rows: 78577\n",
       " }),\n",
       " {'question': [22866,\n",
       "   25,\n",
       "   29244,\n",
       "   6158,\n",
       "   43679,\n",
       "   1182,\n",
       "   357,\n",
       "   496,\n",
       "   17828,\n",
       "   7156,\n",
       "   1137,\n",
       "   8,\n",
       "   1808,\n",
       "   25,\n",
       "   1374,\n",
       "   867,\n",
       "   6665,\n",
       "   286,\n",
       "   262,\n",
       "   13346,\n",
       "   389,\n",
       "   4697,\n",
       "   621,\n",
       "   7265,\n",
       "   5633,\n",
       "   3280,\n",
       "   25,\n",
       "   220],\n",
       "  'answer': [46506,\n",
       "   327,\n",
       "   28270,\n",
       "   7,\n",
       "   28104,\n",
       "   16034,\n",
       "   1182,\n",
       "   33411,\n",
       "   2479,\n",
       "   1875,\n",
       "   7265]})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('b-mc2/sql-create-context', split='train')\n",
    "\n",
    "\n",
    "def f(data):\n",
    "    question = 'context: ' + data['context'] + ' question: ' + data[\n",
    "        'question'] + ' answer: '\n",
    "    answer = data['answer']\n",
    "\n",
    "    question = tokenizer.encode(question, add_special_tokens=False)\n",
    "    answer = tokenizer.encode(answer, add_special_tokens=False)\n",
    "\n",
    "    return {'question': question, 'answer': answer}\n",
    "\n",
    "\n",
    "dataset = dataset.map(f, remove_columns=['context'])\n",
    "\n",
    "f = lambda data: len(data['question']) + len(data['answer']) < 500\n",
    "dataset = dataset.filter(f)\n",
    "\n",
    "dataset, dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45dd9a8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[22866,    25, 29244,  6158, 43679,  3084,    62,  3672,    62,  1270,\n",
       "           357,   268, 48108, 17828,  7156,  1137,    11,  1524,   569, 31315,\n",
       "          1503,     8,  1808,    25,  1867,   318,   262, 20753,   329,   262,\n",
       "          1524, 39874,    30,  3280,    25,   220, 46506, 35683,     7,   268,\n",
       "         48108,     8, 16034,  3084,    62,  3672,    62,  1270, 33411,  1524,\n",
       "           796,   366,  8929,  1044,     1, 50256,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [22866,    25, 29244,  6158, 43679,  3084,    62,  2075,  3720,  3312,\n",
       "            16,    62,    21,   357, 27729,   834, 17618, 17828,  7156,  1137,\n",
       "            11,  2137,   569, 31315,  1503,     8,  1808,    25,  1867,   318,\n",
       "           262,  4511,  2298,  1271,   329,  2137,   836,  2318,   527,    30,\n",
       "          3280,    25,   220, 46506, 25882,     7, 27729,   834, 17618,     8,\n",
       "         16034,  3084,    62,  2075,  3720,  3312,    16,    62,    21, 33411,\n",
       "          2137,   796,   366,  3987, 35338,     1, 50256,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [22866,    25, 29244,  6158, 43679,  3084,    62,  3672,    62,    24,\n",
       "           357,  2875,   569, 31315,  1503,    11,   267,  6760,   291,    62,\n",
       "         19966,   569, 31315,  1503,     8,  1808,    25,  1867,   373,   262,\n",
       "          1502,   286,   262, 11790,   267,  6760,   291,  1830,    30,  3280,\n",
       "            25,   220, 46506,  1502, 16034,  3084,    62,  3672,    62,    24,\n",
       "         33411,   267,  6760,   291,    62, 19966,   796,   366,    83,   482,\n",
       "          8226,     1, 50256,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [22866,    25, 29244,  6158, 43679,  3084,    62,  1558,  2327,  3365,\n",
       "          1238,    62,    16,   357,  6230,   834, 17618, 17828,  7156,  1137,\n",
       "            11,  7924,    62,  1525,   569, 31315,  1503,     8,  1808,    25,\n",
       "           554,   543,  1622,   750,  3362,  5108, 14579,   717,  1277,   281,\n",
       "          4471,    30,  3280,    25,   220, 46506, 20625,     7,  6230,   834,\n",
       "         17618,     8, 16034,  3084,    62,  1558,  2327,  3365,  1238,    62,\n",
       "            16, 33411,  7924,    62,  1525,   796,   366, 12041,  5108, 14579,\n",
       "             1, 50256],\n",
       "        [22866,    25, 29244,  6158, 43679,  3084,    62,  3672,    62,  1270,\n",
       "           357,   268, 48108, 17828,  7156,  1137,    11,  1524,   569, 31315,\n",
       "          1503,     8,  1808,    25,  1867,   318,   262, 20753,   329,   262,\n",
       "          1524, 39874,    30,  3280,    25,   220,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [22866,    25, 29244,  6158, 43679,  3084,    62,  2075,  3720,  3312,\n",
       "            16,    62,    21,   357, 27729,   834, 17618, 17828,  7156,  1137,\n",
       "            11,  2137,   569, 31315,  1503,     8,  1808,    25,  1867,   318,\n",
       "           262,  4511,  2298,  1271,   329,  2137,   836,  2318,   527,    30,\n",
       "          3280,    25,   220,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [22866,    25, 29244,  6158, 43679,  3084,    62,  3672,    62,    24,\n",
       "           357,  2875,   569, 31315,  1503,    11,   267,  6760,   291,    62,\n",
       "         19966,   569, 31315,  1503,     8,  1808,    25,  1867,   373,   262,\n",
       "          1502,   286,   262, 11790,   267,  6760,   291,  1830,    30,  3280,\n",
       "            25,   220,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [22866,    25, 29244,  6158, 43679,  3084,    62,  1558,  2327,  3365,\n",
       "          1238,    62,    16,   357,  6230,   834, 17618, 17828,  7156,  1137,\n",
       "            11,  7924,    62,  1525,   569, 31315,  1503,     8,  1808,    25,\n",
       "           554,   543,  1622,   750,  3362,  5108, 14579,   717,  1277,   281,\n",
       "          4471,    30,  3280,    25,   220,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "       device='cuda:0'), 'answer_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "       device='cuda:0')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data():\n",
    "    data = random.choices(dataset, k=b)\n",
    "    question = [i['question'] for i in data]\n",
    "    answer = [i['answer'] for i in data]\n",
    "\n",
    "    chosen = [\n",
    "        q + a + [tokenizer.eos_token_id] for q, a in zip(question, answer)\n",
    "    ]\n",
    "    \n",
    "    #rejected直接定义为空\n",
    "    rejected = [q for q, a in zip(question, answer)]\n",
    "    data = chosen + rejected\n",
    "\n",
    "    data = [{'input_ids': i} for i in data]\n",
    "    data = tokenizer.pad(data, return_tensors='pt').to(device)\n",
    "\n",
    "    data['answer_mask'] = data['attention_mask'].clone()\n",
    "\n",
    "    for i, q in enumerate(question):\n",
    "        data['answer_mask'][i, :len(q)] = 0\n",
    "        data['answer_mask'][i + b, :len(q)] = 0\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c47306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_actor = AutoModelForCausalLM.from_pretrained('model/actor').to(device)\n",
    "model_actor_ref = AutoModelForCausalLM.from_pretrained('model/actor').to(\n",
    "    device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9e4634c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.9515, -9.2023, -6.3256, -6.8593], device='cuda:0',\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prob_diff(actor, input_ids, attention_mask, answer_mask):\n",
    "    prob = actor(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "\n",
    "    #偏移以对齐\n",
    "    input_ids = input_ids[:, 1:]\n",
    "    answer_mask = answer_mask[:, 1:]\n",
    "    prob = prob[:, :-1]\n",
    "\n",
    "    #取所有字的预测概率,因为要求联合概率,所以取对数\n",
    "    prob = (prob.softmax(2) + 1e-8).log()\n",
    "\n",
    "    prob = prob.gather(2, index=input_ids.unsqueeze(2)).squeeze(2)\n",
    "\n",
    "    #取答案部分的联合概率\n",
    "    prob = (prob * answer_mask).sum(1)\n",
    "\n",
    "    #两部分的概率求差,这部分数据即可视为loss,这部分数据是越大越好\n",
    "    return prob[:b] - prob[b:]\n",
    "\n",
    "\n",
    "get_prob_diff(model_actor, **get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb049323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6931471824645996\n",
      "SELECT gpu‡ FROM table_name_31 WHERE application = \"cushaw\"\n",
      "SELECT gpu‡ FROM table_name_31 WHERE application = \"cushawn\"<|endoftext|>\n",
      "200 0.4377593994140625\n",
      "SELECT field FROM table_name_63 WHERE date = \"july 12\"\n",
      "SELECT field FROM table_name_63 WHERE date = \"july 12\"<|endoftext|>\n",
      "400 0.5559206008911133\n",
      "SELECT production_code__order_they_were_made___number FROM table_2342078_2 WHERE episode__number = 13\n",
      "SELECT COUNT(production_code__order_they_were_made___number) FROM table_2342078_2 WHERE episode__number = 13<|endoftext|>\n",
      "600 0.45148441195487976\n",
      "SELECT home_team FROM table_name_70 WHERE away_team = \"melbourne\"\n",
      "SELECT home_team FROM table_name_70 WHERE away_team = \"melbourne\"<|endoftext|>\n",
      "800 0.4183880388736725\n",
      "SELECT AVG(game) FROM table_name_77 WHERE record = \"30-22\"\n",
      "SELECT SUM(game) FROM table_name_77 WHERE record = \"30-22\"<|endoftext|>\n",
      "1000 0.647190272808075\n",
      "SELECT type FROM table_name_87 WHERE location = \"brazil\" AND entered_service = \"1976/1997\"\n",
      "SELECT type FROM table_name_87 WHERE location = \"brazil\" AND entered_service = \"azinge\"<|endoftext|>\n",
      "1200 0.4110472500324249\n",
      "SELECT MIN(meas_num) FROM table_256286_23 WHERE description = \"Tax Supervising and Conservation Bill\"\n",
      "SELECT MIN(meas_num) FROM table_256286_23 WHERE description = \"Tax supervising and conservation bill\"<|endoftext|>\n",
      "1400 0.484164834022522\n",
      "SELECT winning_driver FROM table_name_21 WHERE fastest_lap = \"giuseppe farina\" AND race = \"british grand prix\"\n",
      "SELECT winning_driver FROM table_name_21 WHERE fastest_lap = \"giuseppe farina\" AND race = \"british grand prix\"<|endoftext|>\n",
      "1600 0.4394538998603821\n",
      "SELECT surface FROM table_name_92 WHERE semifinalists = \"wally masur malivai washington\"\n",
      "SELECT surface FROM table_name_92 WHERE semifinalists = \"wally masur malivai washington\"<|endoftext|>\n",
      "1800 0.4333847761154175\n",
      "SELECT rank FROM table_name_84 WHERE nationality = \"japan\"\n",
      "SELECT COUNT(rank) FROM table_name_84 WHERE nationality = \"japan\"<|endoftext|>\n",
      "2000 0.5025137662887573\n",
      "SELECT MIN(fa_cup_goals) FROM table_name_46 WHERE league_goals = \"12\" AND total = 14\n",
      "SELECT MIN(fa_cup_goals) FROM table_name_46 WHERE league_goals = 12 AND total = 14<|endoftext|>\n",
      "2200 0.48526448011398315\n",
      "SELECT SUM(year) FROM table_name_52 WHERE category = \"best improved singer (躍進歌手)\"\n",
      "SELECT SUM(year) FROM table_name_52 WHERE category = \"best improved singer (躍進歌手)\"<|endoftext|>\n",
      "2400 0.4763438105583191\n",
      "SELECT MIN(rank) FROM table_name_91 WHERE name = \"maxim podoprigora\"\n",
      "SELECT MIN(rank) FROM table_name_91 WHERE name = \" Maxim Podoprigora\"<|endoftext|>\n",
      "2600 0.4994191527366638\n",
      "SELECT runs FROM table_name_13 WHERE opponent = \"new south wales\" AND season = \"2002/03\"\n",
      "SELECT COUNT(runs) FROM table_name_13 WHERE opponent = \"new south wales\" AND season = \"2002/03\"<|endoftext|>\n",
      "2800 0.4413486421108246\n",
      "SELECT framed_size FROM table_name_22 WHERE date_completed = \"08/87\"\n",
      "SELECT framed_size FROM table_name_22 WHERE date_completed = \"08/87\"<|endoftext|>\n",
      "3000 0.44316160678863525\n",
      "SELECT MAX(season) FROM table_name_44 WHERE podiums = \"0\" AND races = \"16\"\n",
      "SELECT AVG(season) AS Season FROM table_name_44 WHERE podiums = 0 AND races = \"16\"<|endoftext|>\n",
      "3200 0.4659852683544159\n",
      "SELECT venue FROM table_name_3 WHERE tournament = \"universiade\" AND year = 1959\n",
      "SELECT venue FROM table_name_3 WHERE venue = \"universaliade\" AND year = 1959<|endoftext|>\n",
      "3400 0.5183249115943909\n",
      "SELECT surface FROM table_name_10 WHERE result = \"fernando verdasco\"\n",
      "SELECT surface FROM table_name_10 WHERE result = \"fernando verdasco\"<|endoftext|>\n",
      "3600 0.4717128276824951\n",
      "SELECT entrant FROM table_name_65 WHERE chassis = \"m185b m186\"\n",
      "SELECT entrant FROM table_name_65 WHERE chassis = \"m185b m186\"<|endoftext|>\n",
      "3800 0.5481764674186707\n",
      "SELECT skip FROM table_name_17 WHERE lead = \"gordon mcdougall\"\n",
      "SELECT skip FROM table_name_17 WHERE lead = \"gdalley mcougall\"<|endoftext|>\n",
      "4000 0.40263471007347107\n",
      "SELECT 1 AS st_leg FROM table_17968229_1 WHERE home__2nd_leg_ = \"Atlético Tucumán\"\n",
      "SELECT home__2nd_leg_ FROM table_17968229_1 WHERE home__2nd_leg_ = \"Atlético Tucumán\"<|endoftext|>\n",
      "4200 0.4345056116580963\n",
      "SELECT date__to_ FROM table_name_38 WHERE traction_type = \"electric\" AND name_of_system = \"yarmouth light and power company\"\n",
      "SELECT date__to_ FROM table_name_38 WHERE traction_type = \"electric\" AND name_of_system = \"yarmouth light and power company\"<|endoftext|>\n",
      "4400 0.4478015899658203\n",
      "SELECT score FROM table_name_70 WHERE result = \"1-0\"\n",
      "SELECT score FROM table_name_70 WHERE result = \"1-0\"<|endoftext|>\n",
      "4600 0.4473908543586731\n",
      "SELECT LOCATION FROM station EXCEPT SELECT LOCATION FROM station WHERE number_of_platforms >= 15\n",
      "SELECT LOCATION FROM station WHERE number_of_platforms < 15 GROUP BY LOCATION<|endoftext|>\n",
      "4800 0.45472246408462524\n",
      "SELECT COUNT(episode) FROM table_15187735_10 WHERE segment_a = \"s Fire Extinguisher\"\n",
      "SELECT COUNT(episode) FROM table_15187735_10 WHERE segment_a = \"s Fire extinguisher\"<|endoftext|>\n",
      "5000 0.37593168020248413\n",
      "SELECT previous_champion_s_ FROM table_name_98 WHERE date_won = \"july 7, 2010\"\n",
      "SELECT previous_champion_s_ FROM table_name_98 WHERE date_won = \"july 7, 2010\"<|endoftext|>\n",
      "5200 0.4219744801521301\n",
      "SELECT COUNT(points) FROM table_name_80 WHERE score = \"3–0\"\n",
      "SELECT COUNT(points) FROM table_name_80 WHERE score = \"3–0\"<|endoftext|>\n",
      "5400 0.45886242389678955\n",
      "SELECT MAX(wins) FROM table_name_86 WHERE earnings___$__ = 130 OFFSET 002\n",
      "SELECT MAX(wins) FROM table_name_86 WHERE earnings___$__ = \"130,002\"<|endoftext|>\n",
      "5600 0.48913687467575073\n",
      "SELECT top_goalscorer FROM table_2429942_2 WHERE season = \"2001-02\"\n",
      "SELECT top_goalscorer FROM table_2429942_2 WHERE season = \"2001-02\"<|endoftext|>\n",
      "5800 0.3794328570365906\n",
      "SELECT county FROM table_name_72 WHERE school = \"whiteland community\"\n",
      "SELECT county FROM table_name_72 WHERE school = \"whiteland community\"<|endoftext|>\n",
      "6000 0.4075813591480255\n",
      "SELECT MIN(year_completed) FROM table_name_31 WHERE dam_type = \"concrete gravity\" AND impounded_body_of_water = \"deep creek reservoir\"\n",
      "SELECT MIN(year_completed) FROM table_name_31 WHERE dam_type = \"crete gravity\" AND impounded_body_of_water = \"deep creek reservoir\"<|endoftext|>\n",
      "6200 0.4217664897441864\n",
      "SELECT score FROM table_name_89 WHERE record = \"43-26\"\n",
      "SELECT score FROM table_name_89 WHERE record = \"43-26\"<|endoftext|>\n",
      "6400 0.42129695415496826\n",
      "SELECT MAX(year) FROM table_name_92 WHERE championship = \"olympics\" AND event = \"men's eight\" AND nation = \"canada\" AND result = \"silver\"\n",
      "SELECT AVG(year) FROM table_name_92 WHERE medal = \"silver\" AND event = \"olympics, csw\" AND nation = \"olympics\" AND result = \"silver\"<|endoftext|>\n",
      "6600 0.46612808108329773\n",
      "SELECT AVG(top_5) FROM table_name_29 WHERE position = \"52nd\" AND year < 2000\n",
      "SELECT AVG(top_5) FROM table_name_29 WHERE position = \"52nd\" AND year < 2000<|endoftext|>\n",
      "6800 0.3849477171897888\n",
      "SELECT tournament FROM table_name_42 WHERE 1996 = \"qf\"\n",
      "SELECT tournament FROM table_name_42 WHERE 1996 = \"qf\"<|endoftext|>\n",
      "7000 0.4915701448917389\n",
      "SELECT race_winner FROM table_28925058_1 WHERE date = \"May 1\"\n",
      "SELECT race_winner FROM table_28925058_1 WHERE date = \"May 1\"<|endoftext|>\n",
      "7200 0.44166648387908936\n",
      "SELECT date FROM table_name_61 WHERE label = \"alfa records\" AND catalog = \"alca-487\"\n",
      "SELECT date FROM table_name_61 WHERE label = \"alfa records\" AND catalog = \"alca-487\"<|endoftext|>\n",
      "7400 0.45678699016571045\n",
      "SELECT MAX(late_1943) FROM table_1115992_1 WHERE NOT _late_1941 = \"Slovenia\"\n",
      "SELECT MIN(late_1943) FROM table_1115992_1 WHERE _late_1941 = \"Slovenia\"<|endoftext|>\n",
      "7600 0.43189072608947754\n",
      "SELECT nationality FROM table_2679061_4 WHERE player = \"Bob Essensa\"\n",
      "SELECT nationality FROM table_2679061_4 WHERE player = \"Bob Essensa\"<|endoftext|>\n",
      "7800 0.45711979269981384\n",
      "SELECT runner_s__up FROM table_name_97 WHERE tournament = \"alfred dunhill links championship\"\n",
      "SELECT runner_s__up FROM table_name_97 WHERE tournament = \"alfour dunhill resorts\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model_actor.parameters(), lr=1e-5)\n",
    "\n",
    "for i in range(8000):\n",
    "    data = get_data()\n",
    "\n",
    "    #两个模型分别计算概率对数\n",
    "    prob_diff = get_prob_diff(model_actor, **data)\n",
    "    with torch.no_grad():\n",
    "        prob_diff_ref = get_prob_diff(model_actor_ref, **data)\n",
    "\n",
    "    #ref部分的概率可以视为常量,理解时可以直接把括号里面的ref部分忽略\n",
    "    loss = 0.1 * (prob_diff - prob_diff_ref)\n",
    "\n",
    "    #取sigmoid再取log保持数值稳定\n",
    "    loss = (loss.sigmoid() + 1e-8).log().mean()\n",
    "\n",
    "    #符号取反,因为loss是越小越好,也就是说,上面计算的结果越大越好\n",
    "    loss = -loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i % 200 == 0:\n",
    "        print(i, loss.item())\n",
    "        data = random.choice(dataset)\n",
    "        question = torch.LongTensor(data['question']).unsqueeze(0).to(device)\n",
    "\n",
    "        gen = model_actor.generate(input_ids=question,\n",
    "                                   min_length=-1,\n",
    "                                   max_length=question.shape[1] + 50,\n",
    "                                   pad_token_id=tokenizer.pad_token_id,\n",
    "                                   eos_token_id=tokenizer.eos_token_id,\n",
    "                                   top_k=0.0,\n",
    "                                   top_p=1.0,\n",
    "                                   do_sample=True)\n",
    "        gen = gen[0, question.shape[1]:]\n",
    "        print(tokenizer.decode(data['answer']))\n",
    "        print(tokenizer.decode(gen))\n",
    "\n",
    "model_actor.save_pretrained('model/dpo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cuda117]",
   "language": "python",
   "name": "conda-env-cuda117-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
