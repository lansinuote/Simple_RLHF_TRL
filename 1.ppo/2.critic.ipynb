{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec54a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='lvwerra/distilbert-imdb', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('lvwerra/distilbert-imdb')\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "847c02a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500,\n",
       " {'input_ids': tensor([[  101,  2004,  1037,  5470,  1997,  2381,  1010, 11327,  1010,  1998,\n",
       "           5913,  1000, 17477,  7307,  1000,  2265,  2766,  2033,  1999,  2013,\n",
       "           1996,  2131,  1011,  2175,  1012,  2009,  2038,  4100,  1011, 11519,\n",
       "           5896,  2075,  1010,  1996, 12703,  2024, 10392,  1006,  2045,  2024,\n",
       "          11790,  1007,  1010,  2009,  2038,  3492,  2204,  3772,  1010,   102],\n",
       "         [  101, 24404, 29418, 12338,  1010,  1996,  2269,  1997,  1996,  3842,\n",
       "           1999,  2010,  8795,  2005,  2634,  1005,  1055,  4071,  5998,  6439,\n",
       "           2010,  2219,  2155,  1998,  2365,  1010,  2023,  3185,  2003,  2055,\n",
       "           2010,  2365,  7632,  7941,  2389,  2040,  5683, 15486,  2138,  1997,\n",
       "          24404, 29418, 12338,  1005,  1055,  2326,  2000,  1996,  2554,   102],\n",
       "         [  101,  2004,  1037,  3627,  1010,  1045,  3046,  2000,  2424,  2004,\n",
       "           2172,  1999,  3152,  2004,  1045,  4298,  2064,  2000,  5959,  2068,\n",
       "           1012,  1045,  2081,  2053, 11790,  2007,  1000, 16985,  2102,  1000,\n",
       "           1010,  2725,  2026,  2200,  2190,  2000,  9120,  2009,  2005,  2054,\n",
       "           2009,  2001,  1012,  2021,  2053,  3947,  1010,  2053,  3043,   102],\n",
       "         [  101,  2009,  2038,  1037,  2978,  1997,  2008, 10271, 19483,  3341,\n",
       "           2008,  2001,  5099,  1999,  1996, 17233,  1998,  2029,  3182,  2019,\n",
       "          13216,  5271,  1011,  2011,  3058,  2006,  1996,  5107,  2806,  1012,\n",
       "           3494,  2024, 27423,  9706,  8988, 16530,  1998,  2521, 19053,  3973,\n",
       "           2757,  9739,  1012,  2395,  7415, 12942,  2015,  1999,  5483,   102]],\n",
       "        device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1]], device='cuda:0'), 'labels': tensor([1, 1, 0, 0], device='cuda:0')})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "dataset = load_dataset('imdb')\n",
    "dataset = concatenate_datasets([dataset[i] for i in ['train', 'test']])\n",
    "\n",
    "\n",
    "def f(data):\n",
    "    text = [i['text'] for i in data]\n",
    "    label = [i['label'] for i in data]\n",
    "\n",
    "    data = tokenizer(text,\n",
    "                     padding=True,\n",
    "                     truncation=True,\n",
    "                     max_length=50,\n",
    "                     return_tensors='pt').to(device)\n",
    "\n",
    "    data['labels'] = torch.LongTensor(label).to(device)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset,\n",
    "                                     batch_size=4,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True,\n",
    "                                     collate_fn=f)\n",
    "\n",
    "len(loader), next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "628012d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"_name_or_path\": \"lvwerra/distilbert-imdb\",\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForSequenceClassification\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"NEGATIVE\",\n",
       "    \"1\": \"POSITIVE\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"label2id\": {\n",
       "    \"NEGATIVE\": 0,\n",
       "    \"POSITIVE\": 1\n",
       "  },\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"problem_type\": \"single_label_classification\",\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.43.3\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_critic = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'lvwerra/distilbert-imdb').to(device)\n",
    "\n",
    "model_critic.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d000bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 12500 1.1637792587280273 0.5\n",
      "1000 12500 0.29049110412597656 1.0\n",
      "2000 12500 0.832800030708313 0.5\n",
      "3000 12500 0.1894889622926712 1.0\n",
      "4000 12500 0.2516906261444092 1.0\n",
      "5000 12500 0.4431069493293762 1.0\n",
      "6000 12500 0.557310938835144 0.75\n",
      "7000 12500 0.6333910822868347 0.5\n",
      "8000 12500 0.23886911571025848 0.75\n",
      "9000 12500 0.2795445919036865 1.0\n",
      "10000 12500 0.09735985845327377 1.0\n",
      "11000 12500 0.05919884890317917 1.0\n",
      "12000 12500 0.24701425433158875 0.75\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model_critic.parameters(), lr=1e-5)\n",
    "\n",
    "for i, data in enumerate(loader):\n",
    "    out = model_critic(**data)\n",
    "    out.loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        acc = (out.logits.argmax(1) == data['labels']).sum() / len(\n",
    "            data['labels'])\n",
    "        print(i, len(loader), out.loss.item(), acc.item())\n",
    "        \n",
    "model_critic.save_pretrained('model/critic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cuda117]",
   "language": "python",
   "name": "conda-env-cuda117-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
